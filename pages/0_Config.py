import streamlit as st
import pandas as pd
import requests
import concurrent.futures
import time

st.set_page_config(page_title="Configuration", page_icon="âš™ï¸", layout="wide")

from core.llm_provider import LLMProvider, LocalProviderScanner
from core.ui_utils import inject_custom_css, get_provider_logo_url, get_model_tags, render_status_badge
from core.state.manager import state_manager
inject_custom_css()

st.title("âš™ï¸ å‰§åœºåå°é…ç½® (Studio Settings)")
st.caption("ç®¡ç†æ‚¨çš„ AI æ¼”å‘˜ç­¾çº¦æ¸ é“ä¸æ¨¡å‹åº“ã€‚")

# --- Init Global State ---
state_manager.initialize()

# Helper to sync state and PERSIST
def update_config(index, key, value):
    st.session_state.llm_configs[index][key] = value
    state_manager.db.save_provider(st.session_state.llm_configs[index])

# Helper for Qwen Filtering
def is_valid_qwen_model(model_id):
    # Filter out known non-text models from DashScope
    # Added more keywords based on DashScope documentation
    excluded_keywords = [
        # Image Generation
        "wanx", "wordart", "facechain", "stable-diffusion", "image",
        # Audio/Speech (TTS & ASR)
        "paraformer", "sambert", "cosyvoice", "audio", "speech", "tts", "voice", "synthesis", "recognition",
        # Embeddings & Rerank (Not Chat)
        "embedding", "rerank", "bge", "gte",
        # Video
        "video", "animate",
        # Others
        "docmind"
    ]
    return not any(k in model_id.lower() for k in excluded_keywords)

def run_single_model_test(task):
    """
    Helper to test a single model's latency.
    Includes special handling for "Thinking/Reasoning" models to avoid false positives.
    """
    from openai import OpenAI
    
    model_id = task["model_id"].lower()
    
    # 1. Detect Thinking/Reasoning Models (o1, r1, reasoner)
    is_thinking = any(k in model_id for k in ["o1", "r1", "reason", "think"])
    
    # 2. Adjust Constraints
    timeout_val = 60 if is_thinking else 10
    max_tokens_val = 10 if is_thinking else 1
    
    try:
        client = OpenAI(api_key=task["api_key"], base_url=task["base_url"])
        start = time.time()
        
        client.chat.completions.create(
            model=task["model_id"],
            messages=[{"role": "user", "content": "Hi"}],
            max_tokens=max_tokens_val,
            timeout=timeout_val
        )
        return (time.time() - start) * 1000
    except Exception:
        return -1

# --- Tabs ---
tab_openrouter, tab_general = st.tabs(["ğŸŒ OpenRouter ä¸“å±é…ç½®", "ğŸ¢ é€šç”¨æ¸ é“ç®¡ç†"])

# ==============================================================================
# TAB 1: OpenRouter ä¸“å±é…ç½® (OpenRouter Dedicated Config)
# ==============================================================================
with tab_openrouter:
    st.subheader("ğŸŒ OpenRouter æ¨¡å‹åº“ (Model Registry)")
    st.caption("ç›´æ¥ä» OpenRouter API è·å–æœ€æ–°çš„æ¨¡å‹åˆ—è¡¨ã€ä»·æ ¼ä¸å‚æ•°ä¿¡æ¯ã€‚")

    # --- OpenRouter Configuration Section ---
    or_config_index = -1
    or_config = None
    for i, cfg in enumerate(st.session_state.llm_configs):
        if "openrouter.ai" in cfg.get("base_url", ""):
            or_config_index = i
            or_config = cfg
            break
    
    with st.expander("ğŸ”‘ OpenRouter API è®¾ç½® (API Settings)", expanded=not (or_config and or_config.get("api_key"))):
        col_key, col_btn = st.columns([4, 1])
        with col_key:
            or_api_key = st.text_input("OpenRouter API Key", value=or_config.get("api_key", "") if or_config else "", type="password", label_visibility="collapsed", placeholder="sk-or-...", key="input_or_key")
        with col_btn:
            if st.button("ğŸ’¾ ä¿å­˜é…ç½®", key="btn_save_or_key", use_container_width=True):
                if not or_api_key:
                    st.error("è¯·è¾“å…¥ API Key")
                else:
                    new_conf = {
                        "name": "OpenRouter",
                        "base_url": "https://openrouter.ai/api/v1",
                        "api_key": or_api_key,
                        "model": "default",
                        "fetched_models": [],
                        "status": "unknown"
                    }
                    
                    if or_config_index != -1:
                        st.session_state.llm_configs[or_config_index]["api_key"] = or_api_key
                        st.session_state.llm_configs[or_config_index]["base_url"] = "https://openrouter.ai/api/v1"
                        state_manager.db.save_provider(st.session_state.llm_configs[or_config_index])
                    else:
                        st.session_state.llm_configs.append(new_conf)
                        state_manager.db.save_provider(new_conf)
                    
                    st.success("å·²ä¿å­˜")
                    st.rerun()

    st.divider()

    # Constants
    OPENROUTER_MODELS_API = "https://openrouter.ai/api/v1/models"

    def fetch_openrouter_models():
        from requests.adapters import HTTPAdapter
        from urllib3.util.retry import Retry
        
        session = requests.Session()
        retry = Retry(
            total=3,
            backoff_factor=1,
            status_forcelist=[500, 502, 503, 504],
            allowed_methods=["GET"]
        )
        adapter = HTTPAdapter(max_retries=retry)
        session.mount("https://", adapter)
        session.mount("http://", adapter)

        try:
            # Increased timeout to 20s for better stability
            response = session.get(OPENROUTER_MODELS_API, timeout=20) 
            response.raise_for_status()
            data = response.json()
            return data.get("data", [])
        except Exception as e:
            st.error(f"Failed to fetch models: {e}")
            return []

    def process_models_data(models_data):
        import time

        processed = []
        now = time.time()
        # Define "New" as created within last 30 days
        thirty_days_ago = now - (30 * 24 * 60 * 60)

        # Translation Helper
        MODALITY_MAP = {
            "text->text": "æ–‡æœ¬å¯¹è¯ (Text)",
            "text+image->text": "å¤šæ¨¡æ€è§†è§‰ (Vision)",
            "text->image": "æ–‡ç”Ÿå›¾ (Image Gen)",
            "unknown": "æœªçŸ¥ (Unknown)"
        }

        for m in models_data:
            # Pricing
            pricing = m.get("pricing", {})
            prompt_price = float(pricing.get("prompt", 0)) * 1_000_000
            completion_price = float(pricing.get("completion", 0)) * 1_000_000
            
            is_free = (prompt_price == 0 and completion_price == 0)
            
            # Context
            context_len = int(m.get("context_length", 0))

            # New check
            created_ts = m.get("created")
            is_new = False
            if created_ts:
                try:
                    if float(created_ts) > thirty_days_ago:
                        is_new = True
                except:
                    pass

            # Modality
            arch = m.get("architecture", {})
            modality_raw = arch.get("modality", "unknown")
            modality_cn = MODALITY_MAP.get(modality_raw, modality_raw)

            # Tags
            tags = []
            if is_free: tags.append("ğŸ†“ å…è´¹")
            if is_new: tags.append("ğŸ†• æ–°å“")
            if "image" in modality_raw: tags.append("ğŸ‘€ è§†è§‰")
            if context_len >= 128000: tags.append("ğŸ“š é•¿ä¸Šä¸‹æ–‡")
            if (prompt_price + completion_price) < 1.0 and not is_free: tags.append("ğŸ’° ç»æµ")
            if (prompt_price + completion_price) > 10.0: tags.append("ğŸ’ é«˜çº§")

            tag_str = " ".join(tags)

            # Provider extraction
            model_id = m.get("id", "")
            provider_name = model_id.split("/")[0] if "/" in model_id else "Unknown"

            processed.append({
                "é€‰æ‹© (Select)": False, # Checkbox column
                "æ¨¡å‹å‚å•† (Provider)": provider_name,
                "ID": model_id, # Kept for search, hidden in view
                "æ¨¡å‹åç§° (Name)": m.get("name"),
                "æ ‡ç­¾ (Tags)": tag_str,
                "ä¸Šä¸‹æ–‡é•¿åº¦ (Context)": context_len,
                "è¾“å…¥ä»·æ ¼ ($/1M)": prompt_price, # Keep as float for sorting
                "è¾“å‡ºä»·æ ¼ ($/1M)": completion_price, # Keep as float for sorting
                "æ¨¡æ€ (Modality)": modality_cn,
                "æ¨¡å‹æè¿° (Description)": m.get("description", "")
            })
        return pd.DataFrame(processed)

    # --- OpenRouter UI ---
    
    should_rerun = False

    # --- Auto-Translation Processor (Real-time Feedback) ---
    if "trans_queue" in st.session_state and st.session_state.trans_queue:
        # Get OpenRouter Config
        or_config = None
        for cfg in st.session_state.llm_configs:
            if "openrouter.ai" in cfg.get("base_url", ""):
                or_config = cfg
                break
        
        if not or_config or not or_config.get("api_key"):
            st.error("OpenRouter é…ç½®ä¸¢å¤±ï¼Œç¿»è¯‘ä¸­æ­¢ã€‚")
            st.session_state.trans_queue = [] # Stop
        else:
            # Progress UI
            total = st.session_state.get("trans_total", 1)
            remaining = len(st.session_state.trans_queue)
            completed = total - remaining
            
            st.info(f"ğŸ”„ æ­£åœ¨ç¿»è¯‘ä¸­... ({completed}/{total}) - å®æ—¶æ›´æ–°ä¸­")
            st.progress(completed / total)
            
            # Process One Item
            target_model_id = st.session_state.trans_queue[0]
            translator_id = st.session_state.get("trans_translator_id")
            
            # Find row in DF
            mask = st.session_state.or_models_df["ID"] == target_model_id
            
            if mask.any():
                current_desc = st.session_state.or_models_df.loc[mask, "æ¨¡å‹æè¿° (Description)"].values[0]
                model_name = st.session_state.or_models_df.loc[mask, "æ¨¡å‹åç§° (Name)"].values[0]
                
                # Check if needs translation (not empty)
                if current_desc:
                    try:
                        from core.llm_provider import LLMProvider
                        provider = LLMProvider(
                            api_key=or_config["api_key"],
                            base_url=or_config["base_url"],
                            model_name=translator_id
                        )
                        
                        prompt = f"Translate the following AI model description to Chinese. Keep it concise and professional. Do not add explanations. Text: {current_desc}"
                        
                        if provider.client:
                            resp = provider.client.chat.completions.create(
                                model=provider.model_name,
                                messages=[{"role": "user", "content": prompt}],
                                temperature=0.3,
                                max_tokens=500
                            )
                            translated_text = resp.choices[0].message.content.strip()
                            
                            # Update State (This is the "Show where" part - updating the source of truth)
                            st.session_state.or_models_df.loc[mask, "æ¨¡å‹æè¿° (Description)"] = translated_text
                            
                    except Exception as e:
                        error_msg = f"æ¨¡å‹ [{model_name}] ç¿»è¯‘å¤±è´¥: {str(e)}"
                        if "translation_errors" not in st.session_state:
                            st.session_state.translation_errors = []
                        st.session_state.translation_errors.append(error_msg)

            # Move to next
            st.session_state.trans_queue.pop(0)
            
            # Check if done
            if not st.session_state.trans_queue:
                st.success("å…¨éƒ¨ç¿»è¯‘å®Œæˆï¼")
                # Uncheck translator
                if translator_id:
                    mask_trans = st.session_state.or_models_df["ID"] == translator_id
                    st.session_state.or_models_df.loc[mask_trans, "é€‰æ‹© (Select)"] = False
                # Allow fall-through to render the final state
            else:
                should_rerun = True

    # Display persistent errors if any
    if "translation_errors" in st.session_state and st.session_state.translation_errors:
        with st.container():
            st.error(f"âš ï¸ ç¿»è¯‘è¿‡ç¨‹ä¸­å‘ç”Ÿäº† {len(st.session_state.translation_errors)} ä¸ªé”™è¯¯ï¼š")
            for err in st.session_state.translation_errors:
                st.text(f"âŒ {err}")
            if st.button("æ¸…é™¤æŠ¥é”™ä¿¡æ¯ (Clear Errors)", key="clear_trans_errors"):
                st.session_state.translation_errors = []
                st.rerun()

    col1, col2, col3 = st.columns([2, 4, 2])
    
    with col1:
        if st.button("ğŸ”„ åˆ·æ–° OpenRouter æ¨¡å‹åˆ—è¡¨", type="primary", key="btn_refresh_or", use_container_width=True):
            with st.spinner("Fetching from OpenRouter..."):
                models = fetch_openrouter_models()
                if models:
                    st.session_state.openrouter_models = models
                    st.success(f"æˆåŠŸè·å– {len(models)} ä¸ªæ¨¡å‹ã€‚")
                else:
                    st.warning("æœªæ‰¾åˆ°æ¨¡å‹æˆ–å‘ç”Ÿé”™è¯¯ã€‚")

    with col2:
        # Search/Filter
        search_term = st.text_input("ğŸ” æœç´¢æ¨¡å‹ (Search)", "", key="search_or", label_visibility="collapsed", placeholder="ğŸ” æœç´¢æ¨¡å‹åç§°æˆ–ID...")
        
        # Tag Filter
        all_tags = set()
        if "or_models_df" in st.session_state and not st.session_state.or_models_df.empty:
            for tags_str in st.session_state.or_models_df["æ ‡ç­¾ (Tags)"]:
                if tags_str:
                    for t in tags_str.split():
                        all_tags.add(t)
        sorted_tags = sorted(list(all_tags))
        
        selected_tags = st.multiselect(
            "ğŸ·ï¸ æŒ‰æ ‡ç­¾ç­›é€‰ (Filter by Tags)", 
            options=sorted_tags,
            placeholder="é€‰æ‹©æ ‡ç­¾ä»¥è¿‡æ»¤æ¨¡å‹æ± ...",
        )

    with col3:
        translate_btn = st.button("ğŸŒ ä¸€é”®ç¿»è¯‘æè¿°", help="ä½¿ç”¨å‹¾é€‰çš„æ¨¡å‹ä½œä¸ºç¿»è¯‘å¼•æ“ï¼Œç¿»è¯‘åˆ—è¡¨ä¸­æ‰€æœ‰æ¨¡å‹çš„æè¿°", use_container_width=True)

    if "openrouter_models" in st.session_state and st.session_state.openrouter_models:
        # Check if we need to initialize or update the dataframe in session state
        # We store the dataframe in session state to persist checkbox selections across reruns
        if "or_models_df" not in st.session_state or len(st.session_state.or_models_df) != len(st.session_state.openrouter_models):
             st.session_state.or_models_df = process_models_data(st.session_state.openrouter_models)
        
        df = st.session_state.or_models_df
        
        # Apply Search Filter (create a copy for view, but we need to map back edits)
        # Note: Filtering makes editing tricky in Streamlit. 
        # Strategy: We show the dataframe. If user edits, we update the main DF.
        
        # To handle filtering correctly with data_editor, we usually just filter the view.
        # But data_editor returns the edited dataframe.
        
        filtered_df = df
        
        # 1. Tag Filter (AND Logic)
        if selected_tags:
            def has_all_tags(row_tags_str, selected):
                if not row_tags_str: return False
                row_tags = row_tags_str.split()
                # Check if row_tags contains ALL selected tags (Subset check)
                return set(selected).issubset(set(row_tags))
            
            mask = filtered_df["æ ‡ç­¾ (Tags)"].apply(lambda x: has_all_tags(x, selected_tags))
            filtered_df = filtered_df[mask]

        # 2. Search Filter
        if search_term:
            filtered_df = filtered_df[filtered_df["ID"].str.contains(search_term, case=False) | filtered_df["æ¨¡å‹åç§° (Name)"].str.contains(search_term, case=False)]

        # --- Sync Filtered Result to OpenRouter Provider Config (The Pool) ---
        # Find OpenRouter Config
        or_config_idx = -1
        for i, cfg in enumerate(st.session_state.llm_configs):
            if "openrouter.ai" in cfg.get("base_url", ""):
                or_config_idx = i
                break
        
        if or_config_idx != -1:
            # Get current visible IDs (This is the pool defined by filters)
            visible_ids = filtered_df["ID"].tolist()
            
            # Update if changed (Check lengths first for speed, then set comparison)
            current_stored = st.session_state.llm_configs[or_config_idx].get("fetched_models", [])
            
            # Simple check: if list content changed
            if set(visible_ids) != set(current_stored):
                 st.session_state.llm_configs[or_config_idx]["fetched_models"] = visible_ids
                 # Persist to DB immediately so it's safe
                 state_manager.db.save_provider(st.session_state.llm_configs[or_config_idx])

        # Display Data Editor

        # Display Data Editor
        edited_df = st.data_editor(
            filtered_df,
            column_config={
                "é€‰æ‹© (Select)": st.column_config.CheckboxColumn("é€‰æ‹©", help="å‹¾é€‰ä»¥ç¿»è¯‘æè¿°", default=False, width="small"),
                "æ¨¡å‹å‚å•† (Provider)": st.column_config.TextColumn("å‚å•† (Provider)", width="small"),
                "ID": None, # Hide Model ID
                "æ¨¡å‹åç§° (Name)": st.column_config.TextColumn("æ¨¡å‹åç§° (Name)", width="medium"),
                "æ ‡ç­¾ (Tags)": st.column_config.TextColumn("æ ‡ç­¾ (Tags)", width="small"),
                "ä¸Šä¸‹æ–‡é•¿åº¦ (Context)": st.column_config.NumberColumn("ä¸Šä¸‹æ–‡é•¿åº¦", help="Context Length", format="%d", width="small"),
                "è¾“å…¥ä»·æ ¼ ($/1M)": st.column_config.NumberColumn("è¾“å…¥ä»·æ ¼", help="Input Price ($/1M)", format="$%.4f", width="small"),
                "è¾“å‡ºä»·æ ¼ ($/1M)": st.column_config.NumberColumn("è¾“å‡ºä»·æ ¼", help="Output Price ($/1M)", format="$%.4f", width="small"),
                "æ¨¡æ€ (Modality)": st.column_config.TextColumn("æ¨¡æ€ (Modality)", width="small"),
                "æ¨¡å‹æè¿° (Description)": st.column_config.TextColumn("æ¨¡å‹æè¿° (Description)", width="large"),
            },
            use_container_width=True,
            hide_index=True,
            height=600,
            disabled=["æ¨¡å‹å‚å•† (Provider)", "æ¨¡å‹åç§° (Name)", "æ ‡ç­¾ (Tags)", "ä¸Šä¸‹æ–‡é•¿åº¦ (Context)", "è¾“å…¥ä»·æ ¼ ($/1M)", "è¾“å‡ºä»·æ ¼ ($/1M)", "æ¨¡æ€ (Modality)", "æ¨¡å‹æè¿° (Description)"],
            key="or_editor"
        )
        
        # Handle Translation Logic
        if translate_btn:
            # Clear previous errors
            st.session_state.translation_errors = []

            # 1. Identify the Translator Model (The one checked by user)
            selected_rows = edited_df[edited_df["é€‰æ‹© (Select)"] == True]
            
            if selected_rows.empty:
                st.warning("è¯·å‹¾é€‰ä¸€ä¸ªæ¨¡å‹ä½œä¸ºã€ç¿»è¯‘å¼•æ“ã€‘ï¼(Please select a model to act as the translator)")
            elif len(selected_rows) > 1:
                st.warning("è¯·åªå‹¾é€‰ä¸€ä¸ªæ¨¡å‹ä½œä¸ºç¿»è¯‘å¼•æ“ï¼(Please select only ONE model)")
            else:
                # Get the translator model details
                translator_row = selected_rows.iloc[0]
                translator_model_id = translator_row["ID"]
                translator_name = translator_row["æ¨¡å‹åç§° (Name)"]
                
                # 2. Find OpenRouter Config (to get API Key check)
                or_config = None
                for cfg in st.session_state.llm_configs:
                    if "openrouter.ai" in cfg.get("base_url", ""):
                        or_config = cfg
                        break
                
                if not or_config or not or_config.get("api_key"):
                    st.error("æœªæ‰¾åˆ° OpenRouter é…ç½®æˆ– API Keyï¼è¯·å…ˆåœ¨é¡µé¢é¡¶éƒ¨çš„â€œOpenRouter API è®¾ç½®â€ä¸­å¡«å†™ Keyã€‚")
                else:
                    # 3. Initialize Auto-Translation Queue
                    # We want to translate ALL rows currently visible in the editor (filtered or not)
                    # edited_df contains the current view
                    target_ids = edited_df["ID"].tolist()
                    
                    st.session_state.trans_queue = target_ids
                    st.session_state.trans_total = len(target_ids)
                    st.session_state.trans_translator_id = translator_model_id
                    
                    st.info(f"å³å°†ä½¿ç”¨ [{translator_name}] ç¿»è¯‘ {len(target_ids)} ä¸ªæ¨¡å‹...")
                    st.rerun()

    else:
        st.info("ç‚¹å‡»ä¸Šæ–¹æŒ‰é’®è·å– OpenRouter æ¨¡å‹åˆ—è¡¨ã€‚")
    
    if should_rerun:
        st.rerun()



# ==============================================================================
# TAB 2: é€šç”¨æ¸ é“ç®¡ç† (General Provider Management)
# ==============================================================================
with tab_general:
    # --- Presets ---
    PRESETS = {
        "Custom (è‡ªå®šä¹‰)": {"name": "New Provider", "base_url": ""},
        "OpenAI": {"name": "OpenAI", "base_url": "https://api.openai.com/v1"},
        "DeepSeek": {"name": "DeepSeek", "base_url": "https://api.deepseek.com/v1"},
        "SiliconFlow (ç¡…åŸºæµåŠ¨)": {"name": "SiliconFlow", "base_url": "https://api.siliconflow.cn/v1"},
        "Claude (Anthropic)": {"name": "Claude", "base_url": "https://api.anthropic.com/v1"},
        "Google Gemini": {"name": "Google", "base_url": "https://generativelanguage.googleapis.com/v1beta/openai"},
        "Moonshot (Kimi)": {"name": "Moonshot", "base_url": "https://api.moonshot.cn/v1"},
        "AliCloud Qwen (é€šä¹‰åƒé—®)": {"name": "Qwen", "base_url": "https://dashscope.aliyuncs.com/compatible-mode/v1"},
        "Zhipu ChatGLM (æ™ºè°±)": {"name": "ChatGLM", "base_url": "https://open.bigmodel.cn/api/paas/v4/"},
        "ByteDance Ark (ç«å±±å¼•æ“)": {"name": "ByteDance", "base_url": "https://ark.cn-beijing.volces.com/api/v3"},
        "01.AI (é›¶ä¸€ä¸‡ç‰©)": {"name": "01.AI", "base_url": "https://api.lingyiwanwu.com/v1"},
        "Baichuan (ç™¾å·æ™ºèƒ½)": {"name": "Baichuan", "base_url": "https://api.baichuan-ai.com/v1"},
        "Tencent Hunyuan (è…¾è®¯æ··å…ƒ)": {"name": "Hunyuan", "base_url": "https://api.hunyuan.cloud.tencent.com/v1"},
        "Xiaomi MiLM (å°ç±³)": {"name": "Xiaomi", "base_url": "https://api.ai.mi.com/v1"},
        "Xiaomi MiMo (å°ç±³MiMo)": {"name": "MiMo", "base_url": "https://api.xiaomimimo.com/v1"},
        "Minimax (æµ·èº)": {"name": "Minimax", "base_url": "https://api.minimax.chat/v1"},
        "StepFun (é˜¶è·ƒæ˜Ÿè¾°)": {"name": "StepFun", "base_url": "https://api.stepfun.com/v1"},
        "Groq": {"name": "Groq", "base_url": "https://api.groq.com/openai/v1"},
        "Together AI": {"name": "Together", "base_url": "https://api.together.xyz/v1"},
        "Mistral AI": {"name": "Mistral", "base_url": "https://api.mistral.ai/v1"},
        "Perplexity": {"name": "Perplexity", "base_url": "https://api.perplexity.ai"},
    }

    # --- Sidebar: Provider Management ---
    with st.sidebar:
        st.header("ğŸ¢ æ¸ é“ç®¡ç† (Providers)")
        
        # Add New with Presets
        with st.expander("â• æ–°å¢æœåŠ¡å•†", expanded=False):
            preset_choice = st.selectbox("é€‰æ‹©é¢„è®¾æˆ–è‡ªå®šä¹‰", list(PRESETS.keys()))
            if st.button("ç¡®è®¤æ·»åŠ ", use_container_width=True):
                p = PRESETS[preset_choice]
                new_provider = {
                    "name": p["name"], 
                    "api_key": "", 
                    "base_url": p["base_url"], 
                    "model": "default", 
                    "status": "unknown", 
                    "fetched_models": []
                }
                # Avoid name collision
                base_name = new_provider["name"]
                counter = 1
                while any(c["name"] == new_provider["name"] for c in st.session_state.llm_configs):
                    new_provider["name"] = f"{base_name} ({counter})"
                    counter += 1
                    
                st.session_state.llm_configs.append(new_provider)
                state_manager.db.save_provider(new_provider)
                st.rerun()
            
        if st.button("ğŸ” æ‰«ææœ¬åœ° (Ollama/LM Studio)", use_container_width=True):
            with st.spinner("Scanning for local providers..."):
                detected = LocalProviderScanner.scan_common_ports()
                new_count = 0
                for d in detected:
                    # Avoid duplicates
                    if not any(c["base_url"] == d["base_url"] for c in st.session_state.llm_configs):
                        st.session_state.llm_configs.append(d)
                        state_manager.db.save_provider(d)
                        new_count += 1
                if new_count > 0:
                    st.success(f"å‘ç° {new_count} ä¸ªæ–°æœ¬åœ°æœåŠ¡ç«¯")
                else:
                    st.info("æœªå‘ç°æ–°çš„æœ¬åœ°æœåŠ¡ç«¯")
                st.rerun()

        if st.button("ğŸ—‘ï¸ æ¸…ç©ºæ‰€æœ‰é…ç½®", use_container_width=True, type="secondary"):
            for cfg in st.session_state.llm_configs:
                state_manager.db.delete_provider(cfg["name"])
            st.session_state.llm_configs = []
            st.rerun()

        # Loop Configs (using list copy to allow safe mutation if needed, though we operate on index)
        for i, config in enumerate(st.session_state.llm_configs):
            # Skip OpenRouter in General Tab (Managed in Tab 1)
            if config.get("name") == "OpenRouter" or "openrouter.ai" in config.get("base_url", ""):
                continue

            status_html = render_status_badge(config.get("status", "unknown"))
            model_count = len(config.get("fetched_models", []))
            
            with st.expander(f"{config['name']} ({model_count} models)", expanded=False):
                # Header with Delete
                c_head_1, c_head_2 = st.columns([4, 1])
                with c_head_1:
                    st.markdown(status_html, unsafe_allow_html=True)
                with c_head_2:
                    if st.button("ğŸ—‘ï¸", key=f"del_{i}"):
                        target = st.session_state.llm_configs.pop(i)
                        state_manager.db.delete_provider(target["name"])
                        st.rerun()

                # Inputs
                new_name = st.text_input("Name", config["name"], key=f"name_{i}")
                if new_name != config["name"]: update_config(i, "name", new_name)
                
                new_url = st.text_input("Base URL", config["base_url"], key=f"url_{i}")
                if new_url != config["base_url"]: update_config(i, "base_url", new_url)

                new_key = st.text_input("API Key", config["api_key"], type="password", key=f"key_{i}")
                if new_key != config["api_key"]: update_config(i, "api_key", new_key)

                # Test Connection Button
                if st.button(f"ğŸ”— è¿æ¥å¹¶åœ¨äº‘ç«¯è·å–æ¨¡å‹", key=f"conn_{i}", use_container_width=True):
                    if not new_key or not new_url:
                        st.error("è¯·è¡¥å…¨ API Key å’Œ URL")
                    else:
                        with st.spinner("Connecting..."):
                            # Use the current selected model for check OR default
                            current_model = config.get("model", "default")
                            provider = LLMProvider(new_key, new_url, current_model)
                            
                            # 1. Check connection
                            res = provider.check_connection()
                            if res["status"]:
                                config["status"] = "success"
                                # 2. Fetch Models
                                models = provider.fetch_models()
                                
                                # Qwen Filter: Remove non-text models
                                # More robust check: Check name (case-insensitive) OR url
                                is_qwen = "qwen" in config.get("name", "").lower() or "dashscope" in new_url.lower()
                                
                                if is_qwen and models:
                                    original_count = len(models)
                                    models = [m for m in models if is_valid_qwen_model(m)]
                                    filtered_count = len(models)
                                    
                                    if filtered_count < original_count:
                                        st.toast(f"ğŸ§¹ å·²è‡ªåŠ¨è¿‡æ»¤ {original_count - filtered_count} ä¸ªéæ–‡æœ¬æ¨¡å‹ (å¦‚ Wanx/CosyVoice)")

                                if models:
                                    config["fetched_models"] = models
                                    # If the current model is not in the list, set it to the first one
                                    if config.get("model") not in models:
                                        config["model"] = models[0]
                                    st.success(f"å·²è¿æ¥ï¼è·å–åˆ° {len(models)} ä¸ªæ¨¡å‹")
                                else:
                                    config["fetched_models"] = []
                                    st.warning("å·²è¿æ¥ï¼Œä½†æœªèƒ½è·å–åˆ°æ¨¡å‹åˆ—è¡¨ã€‚è¯·åœ¨ä¸‹æ–¹æ‰‹åŠ¨è¾“å…¥ã€‚")
                            else:
                                config["status"] = "fail"
                                st.error(f"è¿æ¥å¤±è´¥: {res['message']}")
                            
                            # PERSIST status/models
                            state_manager.db.save_provider(config)
                            st.rerun()

                # Connection Success UI: Model Selection
                if config.get("status") == "success":
                    models = config.get("fetched_models", [])
                    if models:
                        selected_model = st.selectbox(
                            "é€‰æ‹©æ´»è·ƒæ¨¡å‹ (Active Model)", 
                            options=models, 
                            index=models.index(config["model"]) if config.get("model") in models else 0,
                            key=f"select_m_{i}"
                        )
                        if selected_model != config.get("model"):
                            config["model"] = selected_model
                            state_manager.db.save_provider(config)
                            st.rerun()
                    else:
                        # Manual Model Input (fallback)
                        st.info("ğŸ’¡ è‡ªåŠ¨è·å–å¤±è´¥ï¼Œè¯·æ‰‹åŠ¨å½•å…¥æ¨¡å‹ ID")
                        m_input = st.text_input("æ¨¡å‹ ID (å¦‚ mimo-v2-flash)", key=f"manual_m_{i}")
                        if st.button("é”å®šæ‰‹åŠ¨æ¨¡å‹", key=f"btn_m_{i}", use_container_width=True):
                            if m_input:
                                config["fetched_models"] = [m_input]
                                config["model"] = m_input
                                state_manager.db.save_provider(config)
                                st.rerun()

    # --- Main Area: Model Registry ---

    st.subheader("ğŸŠ æ¨¡å‹å¤‡æˆ˜æ±  (Prep Pool)")
    st.info("åœ¨æ­¤æŸ¥çœ‹å„æœåŠ¡å•†æä¾›çš„æ¨¡å‹ã€‚ä½ å¯ä»¥ç‚¹å‡» â­ æ”¶è—æ¨¡å‹ï¼Œæ”¶è—çš„æ¨¡å‹å°†ä¼˜å…ˆæ˜¾ç¤ºå¹¶ç”¨äºå¯¼æ¼”é€‰è§’ã€‚")

    # --- Initialize Favorites in Session State ---
    if "favorite_models" not in st.session_state:
        st.session_state.favorite_models = set()
        
    if "model_test_results" not in st.session_state:
        st.session_state.model_test_results = {}

    def logo_html(url):
        return f'<img src="{url}" style="width:24px; height:24px; border-radius:4px; vertical-align:middle;">'

    # Aggregate all fetched models
    all_rows = []
    has_any_success = False

    # Heartbeat Check & Test Response
    col_hb, col_test = st.columns([1, 1])
    
    with col_hb:
        if st.button("ğŸ’“ åˆ·æ–°å…¨å±€è¿è´¯æ€§ (Heartbeat)", use_container_width=True):
            with st.spinner("Checking provider status..."):
                heartbeats = LocalProviderScanner.run_heartbeat(st.session_state.llm_configs)
                # Update local status based on heartbeats
                for hb in heartbeats:
                    for cfg in st.session_state.llm_configs:
                        if cfg.get("name") == hb["id"]:
                            cfg["status"] = "success" if hb["active"] else "fail"
                            cfg["latency"] = hb["latency"]
                            # Persist status change
                            state_manager.db.save_provider(cfg)
                st.rerun()

    with col_test:
        if st.button("âš¡ æµ‹è¯•æ‰€æœ‰æ¨¡å‹å“åº” (Test Response)", help="å‘é€'Hi'å¹¶é™åˆ¶1 tokenï¼Œæ£€æµ‹å®é™…å“åº”é€Ÿåº¦", use_container_width=True):
            tasks = []
            for config in st.session_state.llm_configs:
                # Skip OpenRouter (Tab 1)
                if config.get("name") == "OpenRouter" or "openrouter.ai" in config.get("base_url", ""):
                    continue
                if not config.get("fetched_models"):
                    continue
                
                # Check Key/URL
                if not config.get("api_key") or not config.get("base_url"):
                    continue
                    
                for m_id in config.get("fetched_models"):
                    tasks.append({
                        "api_key": config["api_key"],
                        "base_url": config["base_url"],
                        "model_id": m_id
                    })
            
            if not tasks:
                st.warning("æ²¡æœ‰å¯æµ‹è¯•çš„æ¨¡å‹ (No models found to test).")
            else:
                st.session_state.model_test_results = {} # Reset
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                completed = 0
                total = len(tasks)
                
                with concurrent.futures.ThreadPoolExecutor(max_workers=min(len(tasks), 50)) as executor:
                    future_to_model = {executor.submit(run_single_model_test, t): t["model_id"] for t in tasks}
                    
                    st.toast(f"ğŸš€ å·²å¹¶å‘å‘èµ· {len(tasks)} ä¸ªæµ‹è¯•è¯·æ±‚...", icon="âš¡")
                    
                    for future in concurrent.futures.as_completed(future_to_model):
                        m_id = future_to_model[future]
                        result = future.result()
                        st.session_state.model_test_results[m_id] = result
                        
                        completed += 1
                        progress = completed / total
                        progress_bar.progress(progress)
                        status_text.text(f"Testing... {completed}/{total}")
                
                status_text.empty()
                progress_bar.empty()
                
                # Report
                failed_count = sum(1 for v in st.session_state.model_test_results.values() if v < 0)
                st.success(f"æµ‹è¯•å®Œæˆï¼(å…± {total} ä¸ªæ¨¡å‹ï¼Œ{failed_count} ä¸ªå¤±è´¥)")
                
                # Auto-Clean Button logic will be handled below (outside the loop to be persistent)
                st.rerun()

    if st.session_state.get("model_test_results"):
        failed_models = [m for m, lat in st.session_state.model_test_results.items() if lat < 0]
        if failed_models:
            st.warning(f"âš ï¸ æ£€æµ‹åˆ° {len(failed_models)} ä¸ªæ¨¡å‹å“åº”å¤±è´¥/è¶…æ—¶ (å·²ç”¨çº¢è‰²æ ‡è®°)")
            if st.button(f"ğŸ§¹ ä¸€é”®ç§»é™¤è¿™ {len(failed_models)} ä¸ªæ— æ•ˆæ¨¡å‹ (Clean Failed Models)", type="primary"):
                removed_count = 0
                for cfg in st.session_state.llm_configs:
                    if not cfg.get("fetched_models"): continue
                    
                    original_len = len(cfg["fetched_models"])
                    # Filter out failed models
                    cfg["fetched_models"] = [m for m in cfg["fetched_models"] if m not in failed_models]
                    
                    if len(cfg["fetched_models"]) < original_len:
                        removed_count += (original_len - len(cfg["fetched_models"]))
                        state_manager.db.save_provider(cfg)
                
                st.toast(f"âœ… å·²æˆåŠŸç§»é™¤ {removed_count} ä¸ªæ— æ•ˆæ¨¡å‹ï¼", icon="ğŸ§¹")
                # Clear results to hide button
                st.session_state.model_test_results = {}
                st.rerun()

    for p_idx, config in enumerate(st.session_state.llm_configs):
        # Skip OpenRouter in Prep Pool (Shown in Tab 1)
        if config.get("name") == "OpenRouter" or "openrouter.ai" in config.get("base_url", ""):
            continue

        if config.get("fetched_models"):
            has_any_success = True
            provider_name = config["name"]
            logo_url = get_provider_logo_url(provider_name)
            
            for m_id in config["fetched_models"]:
                tags = get_model_tags(m_id)
                all_rows.append({
                    "Logo": logo_html(logo_url),
                    "Model ID": m_id,
                    "Provider": provider_name,
                    "Tags": tags,
                    "p_index": p_idx,
                    "is_fav": m_id in st.session_state.favorite_models
                })


    if not has_any_success:
        st.warning("âš ï¸ æš‚æ— å¯ç”¨æ¨¡å‹ã€‚è¯·åœ¨å·¦ä¾§ä¾§è¾¹æ é…ç½®æœåŠ¡å•†å¹¶ç‚¹å‡»ã€è¿æ¥ã€‘æŒ‰é’®ã€‚")
    else:
        # Sorting: Favorites first
        all_rows.sort(key=lambda x: x["is_fav"], reverse=True)

        # Filter/Search Bar
        search_q = st.text_input("ğŸ” æœç´¢æ¨¡å‹æˆ–æ ‡ç­¾...", placeholder="ä¾‹å¦‚: gpt-4, vision, deepseek")
        
        if search_q:
            all_rows = [r for r in all_rows if search_q.lower() in r["Model ID"].lower() or any(search_q.lower() in t.lower() for t in r["Tags"])]

        # Headers
        h1, h2, h3, h_lat, h4 = st.columns([1, 4, 3, 1.5, 1])
        h1.write("**çŠ¶æ€**")
        h2.write("**æ¨¡å‹åç§°**")
        h3.write("**ç‰¹æ€§æ ‡ç­¾**")
        h_lat.write("**å“åº” (ms)**")
        h4.write("**æ”¶è—**")
        st.divider()

        for row in all_rows:
            c1, c2, c3, c_lat, c4 = st.columns([1, 4, 3, 1.5, 1])
            
            with c1:
                st.markdown(row["Logo"], unsafe_allow_html=True)
                
            with c2:
                st.write(f"**{row['Model ID']}**")
                st.caption(row["Provider"])
                
            with c3:
                # Render tags as badges
                tags_html = "".join([f'<span style="background:rgba(255,255,255,0.1); border:1px solid rgba(255,255,255,0.2); padding:2px 8px; border-radius:12px; font-size:0.75em; margin-right:4px; color:#ccc;">{t}</span>' for t in row["Tags"]])
                st.markdown(tags_html, unsafe_allow_html=True)
            
            with c_lat:
                lat = st.session_state.model_test_results.get(row["Model ID"])
                if lat is not None:
                    if lat < 0:
                        st.caption("âŒ Error")
                    else:
                        color = "#4CAF50" if lat < 1000 else "#FFC107" if lat < 3000 else "#F44336"
                        st.markdown(f"<span style='color:{color}; font-weight:bold'>{int(lat)}ms</span>", unsafe_allow_html=True)
                else:
                    st.caption("-")

            with c4:
                fav_icon = "â­" if row["is_fav"] else "â˜†"
                if st.button(fav_icon, key=f"fav_{row['Model ID']}_{row['p_index']}"):
                    if row["is_fav"]:
                        st.session_state.favorite_models.remove(row["Model ID"])
                    else:
                        st.session_state.favorite_models.add(row["Model ID"])
                    st.rerun()
                
            st.markdown("<hr style='margin:5px 0; opacity:0.1'>", unsafe_allow_html=True)

    # --- Manual Fallback / Sandbox ---
    with st.expander("ğŸ› ï¸ æ‰‹åŠ¨è°ƒè¯•å·¥å…· (Manual Debug)", expanded=False):
        st.write("å¦‚æœ fetch å¤±è´¥ï¼Œå¯åœ¨æ­¤æ‰‹åŠ¨æµ‹è¯•ä»¥æ’æŸ¥ç½‘ç»œé—®é¢˜ã€‚")
        if st.button("è¿è¡Œä¸€æ¬¡ç®€å•çš„ API Ping"):
            with st.spinner("Pinging all configs..."):
                res = LLMProvider.batch_test_providers(st.session_state.llm_configs)
                st.json(res)
